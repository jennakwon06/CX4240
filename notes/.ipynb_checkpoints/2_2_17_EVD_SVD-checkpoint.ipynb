{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Goals for this session\n",
    "\n",
    "1. Perform EVD\n",
    "2. Explore properties of EVD\n",
    "3. Perform SVD \n",
    "4. Explore properties of SVD\n",
    "5. Be able to explain differences and relationships between EVD and SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.set_printoptions(suppress=True) # make floats display nicer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Eigen Value Decomposition\n",
    "\n",
    "\n",
    "\n",
    "### What are Eigenvalues and Eigenvectors?\n",
    "\n",
    "Think of a (n X n) matrix $A$ as a linear operator. When you multiply a vector $x$ with $A$, you are performing operations upon $x$ such as rotation and scaling. \n",
    "\n",
    "<i> Eigenvectors </i> are special vectors that do not become rotated when multipled with A. Instead, you get them back scaled by a scalar, called <i> eigenvalue</i>. \n",
    "\n",
    "In other words, following holds for an eigenvector $v$ : $Av = \\lambda v$ \n",
    "\n",
    "\n",
    "### What is EVD?\n",
    "\n",
    "Performing Eigen Value Decomposition (EVD) is to do the following:\n",
    "\n",
    "$ A = V W V^{-1} $\n",
    "\n",
    "Where:   \n",
    "$V$ is the square matrix whose columns are the eigenvectors   \n",
    "W is the diagnoal matrix whose diagnomal elements are the corresponding eigenvalues. \n",
    "\n",
    "To demonstrate EVD, We will be using Numpy's linalg.eig function, whose detailed documentation can be found here:  \n",
    "https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.eig.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.35546919,  0.95257726,  0.99315819,  0.7345501 ,  0.55192272],\n",
       "       [ 0.95257726,  0.4760352 ,  0.69373909,  0.64294787,  0.82544256],\n",
       "       [ 0.99315819,  0.69373909,  0.30563077,  0.84714437,  0.91549045],\n",
       "       [ 0.7345501 ,  0.64294787,  0.84714437,  0.34152619,  0.88031864],\n",
       "       [ 0.55192272,  0.82544256,  0.91549045,  0.88031864,  0.85774031]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "A = np.random.rand(n, n)\n",
    "A_sim = np.tril(A) + np.tril(A, -1).T\n",
    "A_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigenvalues [-0.81317633 -0.47990561 -0.2031639   0.13999356  3.69265395]\n",
      "\n",
      "Each column is an eigenvector \n",
      "\n",
      "[[ 0.66085958  0.22283288  0.10497456  0.56127978 -0.43307675]\n",
      " [-0.34385187 -0.287847   -0.7133998   0.31629629 -0.43580658]\n",
      " [-0.6038585   0.51485108  0.39698233  0.08220181 -0.4537964 ]\n",
      " [-0.002065   -0.74353645  0.50445824 -0.1220526  -0.42163293]\n",
      " [ 0.2835157   0.22264665 -0.26070668 -0.75051162 -0.48868359]]\n"
     ]
    }
   ],
   "source": [
    "w, v = np.linalg.eigh(A_sim)\n",
    "print \"Eigenvalues\", w\n",
    "\n",
    "print \"\\nEach column is an eigenvector \\n\"\n",
    "print v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Exploring Properties of EVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property 1. Only diagonalizable matrices can be decomposed \n",
    "\n",
    "This means that the (n x n) matrix must have n linearly independent eigenvectors. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A non-diagnolizable matrix\n",
      "[[ 1.  1.]\n",
      " [ 0.  1.]] \n",
      "\n",
      "After decomposition....\n",
      "Eigenvalues:  [ 1.  1.] \n",
      "\n",
      "A_INVALID CANNOT BE DIAGONLIZED.\n",
      "[[ 1. -1.]\n",
      " [ 0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "A_invalid = np.ones((2,2))\n",
    "A_invalid[1,0] = 0\n",
    "print \"A non-diagnolizable matrix\\n\", A_invalid, '\\n'\n",
    "\n",
    "w_invalid, v_invalid = np.linalg.eig(A_invalid)\n",
    "print \"After decomposition....\"\n",
    "print \"Eigenvalues: \", w_invalid, '\\n\\nA_INVALID CANNOT BE DIAGONLIZED.\\n', v_invalid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property 2. $Av = \\lambda v$  \n",
    "\n",
    "Let $\\lambda_{1} ... \\lambda_{n}$ be series of eigenvalues\n",
    "Let $v_{1} ... v_{n}$ be series of eigenvectors. Then, \n",
    "\n",
    "A$v_{1}$ = $\\lambda_{1}v_{1} \\\\$  \n",
    "A$v_{2}$ = $\\lambda_{2}v_{2} \\\\$  \n",
    "...  \n",
    "A$v_{n}$ = $\\lambda_{n}v_{n} \\\\$\n",
    "\n",
    "\n",
    "<b> In python notation, </b>\n",
    "\n",
    "dot(A[:,:], v[:,i]) = w[i] * v[:,i] for $i \\in \\{0,...,M-1\\}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking eigenvalue  0 ...\n",
      "[-0.53739537  0.2796122   0.49104344  0.00167921 -0.23054826]\n",
      "[-0.53739537  0.2796122   0.49104344  0.00167921 -0.23054826]\n",
      "Checking eigenvalue  1 ...\n",
      "[-0.10693875  0.13813939 -0.24707992  0.35682732 -0.10684938]\n",
      "[-0.10693875  0.13813939 -0.24707992  0.35682732 -0.10684938]\n",
      "Checking eigenvalue  2 ...\n",
      "[-0.02132704  0.14493709 -0.08065248 -0.1024877   0.05296619]\n",
      "[-0.02132704  0.14493709 -0.08065248 -0.1024877   0.05296619]\n",
      "Checking eigenvalue  3 ...\n",
      "[ 0.07857556  0.04427945  0.01150772 -0.01708658 -0.1050668 ]\n",
      "[ 0.07857556  0.04427945  0.01150772 -0.01708658 -0.1050668 ]\n",
      "Checking eigenvalue  4 ...\n",
      "[-1.59920258 -1.60928287 -1.67571306 -1.55694451 -1.8045394 ]\n",
      "[-1.59920258 -1.60928287 -1.67571306 -1.55694451 -1.8045394 ]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    print \"Checking eigenvalue \", i, \"...\"\n",
    "    print np.dot(A_sim, v[:,i])\n",
    "    print np.dot(w[i], v[:, i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property 3. Vector norm of eigenvectors\n",
    "\n",
    "||$V_{i}$|| = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  1.  1.  1.  1.]\n"
     ]
    }
   ],
   "source": [
    "print np.sum(v**2, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Property 4. Similarity between eigenvectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$V_{i}^{T} V_{j}$\n",
    "\n",
    "= 1 if $i = j$,  \n",
    "  0 if $i \\neq j$\n",
    "\n",
    "This means that inner product between eigenvectors are 0 if they are distinct vectors.  \n",
    "Intuitively, this means that they are linearly independent (share no similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices (0, 0) Inner Product  1.00\n",
      "Indices (0, 1) Inner Product  -0.00\n",
      "Indices (0, 2) Inner Product  0.00\n",
      "Indices (0, 3) Inner Product  -0.00\n",
      "Indices (0, 4) Inner Product  -0.00\n",
      "Indices (1, 0) Inner Product  -0.00\n",
      "Indices (1, 1) Inner Product  1.00\n",
      "Indices (1, 2) Inner Product  -0.00\n",
      "Indices (1, 3) Inner Product  -0.00\n",
      "Indices (1, 4) Inner Product  -0.00\n",
      "Indices (2, 0) Inner Product  0.00\n",
      "Indices (2, 1) Inner Product  -0.00\n",
      "Indices (2, 2) Inner Product  1.00\n",
      "Indices (2, 3) Inner Product  -0.00\n",
      "Indices (2, 4) Inner Product  -0.00\n",
      "Indices (3, 0) Inner Product  -0.00\n",
      "Indices (3, 1) Inner Product  -0.00\n",
      "Indices (3, 2) Inner Product  -0.00\n",
      "Indices (3, 3) Inner Product  1.00\n",
      "Indices (3, 4) Inner Product  0.00\n",
      "Indices (4, 0) Inner Product  -0.00\n",
      "Indices (4, 1) Inner Product  -0.00\n",
      "Indices (4, 2) Inner Product  -0.00\n",
      "Indices (4, 3) Inner Product  0.00\n",
      "Indices (4, 4) Inner Product  1.00\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    for j in range(0, 5):\n",
    "        print \"Indices\", (i, j), \"Inner Product \", '{:.2f}'.format(np.inner(v[:, i], v[:, j]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Things to watch out for\n",
    "\n",
    "- Many matrices are NOT diagnolizable and may have complex eigenvalues as seen in lecture.   \n",
    "If you know that eigen values must be REAL Because A is a positive definite matrix, then use \"np.real_if_close(x)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Singular Value Decomposition \n",
    "\n",
    "What if you want to decompose a non-square matrix? You cannot do this with EVD. Why? \n",
    "\n",
    "Think about the dimensions of matrices and vectors when you perform $Av = \\lambda v$. If $A$ was a (n x m) matrix, then v must be a (m x 1) vector, yielding $Av$ to be a (n x 1)  vector. This means the right side of the equation also has to yield a (n x 1) dimensional vector, but $v$ was a (m x 1) vector to begin with. Since A is a non-square matrix, $ m \\neq n$. \n",
    "\n",
    "This means that we need a more genrealized method for matrix decomposition, and this is precisely what SVD is used for. \n",
    "\n",
    "SVD of a matrx A does the following:\n",
    "\n",
    "$A = U S V^{T} $\n",
    "\n",
    "where:\n",
    "$A$ is a (m x n) matrix  \n",
    "$U$ is a $m * m$ orthonormal matrix of 'left-singular' (eigen)vectors of $AA^{T}$,  \n",
    "$V^{T}$ is a $n * n$ orthonormal matrix of 'right-singular' (eigen)vectors of $A^{T}A$  \n",
    "$S$ is a $m * n$ diagonal matrix of the square root of nonzero eigenvalues (called singular values denoted by $\\sigma$)  of $U$ _or_ $V$, ordered by decreasing size. \n",
    "\n",
    "There are many applications with SVD as solving systems of differential equations, linear systems, etc. Later in the course, we will be using an unsupervised learning technique called PCA (Principle Component Analysis) whose fundamentals are based on EVD.\n",
    "\n",
    "We use numpy.linalg.svd to demonstrate SVD technique whose detailed documentation can be found here:  \n",
    "https://docs.scipy.org/doc/numpy-1.10.0/reference/generated/numpy.linalg.svd.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.45409562,  0.95750328,  0.62803589],\n",
       "       [ 0.59879734,  0.70860408,  0.72816308],\n",
       "       [ 0.42239604,  0.30888262,  0.33327031],\n",
       "       [ 0.96237593,  0.47385069,  0.36784239],\n",
       "       [ 0.43818576,  0.28713574,  0.84710018]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = 5\n",
    "m = 3\n",
    "A2 = np.random.rand(n, m)\n",
    "A2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.52364587  0.43663522  0.58583497 -0.4132516   0.1454826 ]\n",
      " [-0.52295883  0.16700892  0.01183859  0.83327795 -0.06426348]\n",
      " [-0.27321724 -0.15272359 -0.0499458  -0.21145363 -0.9245651 ]\n",
      " [-0.46199454 -0.8285112   0.05964336 -0.10210217  0.2935099 ]\n",
      " [-0.4052437   0.26777305 -0.80660109 -0.28237118  0.18367451]] \n",
      "\n",
      "[ 2.24834516  0.54821116  0.4644252 ] \n",
      "\n",
      "[[-0.57309793 -0.57448111 -0.58440586]\n",
      " [-0.8139858   0.31656745  0.48704433]\n",
      " [-0.09479389  0.75482217 -0.64904362]]\n"
     ]
    }
   ],
   "source": [
    "U, s, V = np.linalg.svd(A2, full_matrices=True)\n",
    "\n",
    "print U, '\\n\\n', s, '\\n\\n' ,V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each element of the vector in the middle are singular values. You may have expected a diagnomal matrix whose diagnoals are singular value, but this vector essentially is a compressed form of that diagnomal matrix.\n",
    "\n",
    "In other words, we can re-shape this vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.24834516,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.54821116,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.4644252 ],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        ]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s_reshaped = np.concatenate((np.diag(s), np.zeros((n - len(s), m))))\n",
    "s_reshaped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Exploring Properties of SVD\n",
    "\n",
    "### Property 1. U and V are orthonormal matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -0.  0.]\n",
      " [-0.  1. -0.]\n",
      " [ 0. -0.  1.]] \n",
      "\n",
      "[[ 1.  0. -0.  0.  0.]\n",
      " [ 0.  1.  0. -0.  0.]\n",
      " [-0.  0.  1.  0.  0.]\n",
      " [ 0. -0.  0.  1. -0.]\n",
      " [ 0.  0.  0. -0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "print np.dot(V, V.T), '\\n'\n",
    "print np.dot(U, U.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "@TODO more properties to be discussed in next lecture. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Restoring A From U, s, V \n",
    "\n",
    "We can reconstruct A with U, s_reshaped, V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.45409562  0.95750328  0.62803589]\n",
      " [ 0.59879734  0.70860408  0.72816308]\n",
      " [ 0.42239604  0.30888262  0.33327031]\n",
      " [ 0.96237593  0.47385069  0.36784239]\n",
      " [ 0.43818576  0.28713574  0.84710018]]\n",
      "\n",
      " Compare with original....\n",
      " \n",
      "[[ 0.45409562  0.95750328  0.62803589]\n",
      " [ 0.59879734  0.70860408  0.72816308]\n",
      " [ 0.42239604  0.30888262  0.33327031]\n",
      " [ 0.96237593  0.47385069  0.36784239]\n",
      " [ 0.43818576  0.28713574  0.84710018]]\n"
     ]
    }
   ],
   "source": [
    "A2_restored = np.dot(U, np.dot(s_reshaped, V))\n",
    "print A2_restored\n",
    "print \"\\n Compare with original....\\n \"\n",
    "print A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring Relationship between PCA & SVD\n",
    "\n",
    "Between PCA and SVD, following must hold:\n",
    "\n",
    "$$\n",
    "Given, A = X.T * X \\\\\n",
    "(1)  A = V * D * V.T \\\\ \n",
    "(2)  X = U * S * V.T \\\\\n",
    "(3)  D = S^{2}  \\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing X....\n",
      "\n",
      "[[ 0.03939407 -0.39529962  1.37107684 -1.52521564  1.03173972]\n",
      " [ 1.09709888  0.17177067  0.73687298 -1.72359187 -0.71555706]\n",
      " [-0.14900177  0.94422293 -0.457225   -0.69309068 -0.10124728]]\n",
      "\n",
      " Printing A....\n",
      "\n",
      "[[ 1.22737938  0.03218607  0.93056215 -1.84776343 -0.7293064 ]\n",
      " [ 0.03218607  1.0773239  -0.84713531 -0.3475775  -0.62635804]\n",
      " [ 0.93056215 -0.84713531  2.63188817 -3.04435773  0.93361256]\n",
      " [-1.84776343 -0.3475775  -3.04435773  5.77742641 -0.27012368]\n",
      " [-0.7293064  -0.62635804  0.93361256 -0.27012368  1.58675977]]\n",
      "\n",
      "Printing V, D, V^{T} ....\n",
      "\n",
      "[[-0.03153176  0.74625908  0.50995098  0.32836923 -0.27244591]\n",
      " [ 0.5992715   0.23237271 -0.59776307  0.47846958  0.02495533]\n",
      " [ 0.69119719 -0.17378891  0.28552977 -0.39841567 -0.5017784 ]\n",
      " [ 0.38461723  0.18767565  0.32253609 -0.21253512  0.81709652]\n",
      " [-0.11914466  0.56892492 -0.44392851 -0.67774205 -0.07564503]] \n",
      "[[-0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          0.          0.          0.        ]\n",
      " [ 0.          0.          1.17689032  0.          0.        ]\n",
      " [ 0.          0.          0.          2.84642804  0.        ]\n",
      " [ 0.          0.          0.          0.          8.27745927]] \n",
      "[[-0.03153176  0.5992715   0.69119719  0.38461723 -0.11914466]\n",
      " [ 0.74625908  0.23237271 -0.17378891  0.18767565  0.56892492]\n",
      " [ 0.50995098 -0.59776307  0.28552977  0.32253609 -0.44392851]\n",
      " [ 0.32836923  0.47846958 -0.39841567 -0.21253512 -0.67774205]\n",
      " [-0.27244591  0.02495533 -0.5017784   0.81709652 -0.07564503]]\n",
      "\n",
      "Is A = V * D * V^{T} ? \n",
      "\n",
      "[[ 1.22737938  0.03218607  0.93056215 -1.84776343 -0.7293064 ]\n",
      " [ 0.03218607  1.0773239  -0.84713531 -0.3475775  -0.62635804]\n",
      " [ 0.93056215 -0.84713531  2.63188817 -3.04435773  0.93361256]\n",
      " [-1.84776343 -0.3475775  -3.04435773  5.77742641 -0.27012368]\n",
      " [-0.7293064  -0.62635804  0.93361256 -0.27012368  1.58675977]]\n",
      "\n",
      "Yes! (Compare with A above)\n"
     ]
    }
   ],
   "source": [
    "n = 5\n",
    "d = 3\n",
    "\n",
    "X = np.random.randn(d, n)\n",
    "print \"Printing X....\\n\"\n",
    "print X\n",
    "\n",
    "A = np.dot(X.T, X)\n",
    "print \"\\n Printing A....\\n\"\n",
    "print A \n",
    "\n",
    "w_eig, v_eig = np.linalg.eigh(A)\n",
    "print \"\\nPrinting V, D, V^{T} ....\\n\"\n",
    "print v_eig, '\\n', np.diag(w_eig), '\\n', v_eig.T\n",
    "\n",
    "\n",
    "print \"\\nIs A = V * D * V^{T} ? \\n\"\n",
    "print np.dot(np.dot(v_eig,np.diag(w_eig)), v_eig.T)\n",
    "print \"\\nYes! (Compare with A above)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing X ....\n",
      "\n",
      "[[ 0.03939407 -0.39529962  1.37107684 -1.52521564  1.03173972]\n",
      " [ 1.09709888  0.17177067  0.73687298 -1.72359187 -0.71555706]\n",
      " [-0.14900177  0.94422293 -0.457225   -0.69309068 -0.10124728]]\n",
      "\n",
      "Printing U, S, V^{T} ....\n",
      "\n",
      "[[-0.70657913  0.65054211  0.27846167]\n",
      " [-0.70161028 -0.59280681 -0.39537717]\n",
      " [-0.09213552 -0.47473683  0.87529194]] \n",
      "[[ 2.8770574   0.          0.          0.          0.        ]\n",
      " [ 0.          1.68713605  0.          0.          0.        ]\n",
      " [ 0.          0.          1.08484576  0.          0.        ]] \n",
      "[[-0.27244591  0.02495533 -0.5017784   0.81709652 -0.07564503]\n",
      " [-0.32836923 -0.47846958  0.39841567  0.21253512  0.67774205]\n",
      " [-0.50995098  0.59776307 -0.28552977 -0.32253609  0.44392851]\n",
      " [ 0.74655523  0.18761998 -0.22420741  0.1588484   0.57615297]\n",
      " [ 0.02349799  0.61475373  0.67652581  0.39739118 -0.07693354]]\n",
      "\n",
      " Is X = U * S * V.T?\n",
      "[[ 0.03939407 -0.39529962  1.37107684 -1.52521564  1.03173972]\n",
      " [ 1.09709888  0.17177067  0.73687298 -1.72359187 -0.71555706]\n",
      " [-0.14900177  0.94422293 -0.457225   -0.69309068 -0.10124728]]\n",
      "\n",
      " Yes! (Compare with X above)\n"
     ]
    }
   ],
   "source": [
    "u_svd, s, v_svd = np.linalg.svd(X)\n",
    "\n",
    "print \"Printing X ....\\n\"\n",
    "\n",
    "print X\n",
    "\n",
    "print \"\\nPrinting U, S, V^{T} ....\\n\"\n",
    "s_concat = np.concatenate((np.diag(s), np.zeros((n - d, d)))).T\n",
    "\n",
    "print u_svd, '\\n', s_concat, '\\n', v_svd\n",
    "\n",
    "print \"\\n Is X = U * S * V.T?\"\n",
    "print np.dot(np.dot(u_svd, s_concat), v_svd)\n",
    "\n",
    "print \"\\n Yes! (Compare with X above)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does sqrt(eigenvalues) == singular values hold true?\n",
      "Printing singular values....\n",
      "[1.0848457591655354, 1.6871360462405252, 2.8770573979185197]\n",
      "\n",
      "Printing eigenvalues....\n",
      "[-0.          0.          1.17689032  2.84642804  8.27745927]\n",
      "\n",
      "Printing squared singular values....\n",
      "[1.1768903211794468, 2.8464280385241114, 8.2774592709176833]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "print \"Does sqrt(eigenvalues) == singular values hold true?\"\n",
    "\n",
    "print \"Printing singular values....\"\n",
    "print list(reversed(s))\n",
    "\n",
    "print \"\\nPrinting eigenvalues....\"\n",
    "print w_eig\n",
    "\n",
    "print \"\\nPrinting squared singular values....\"\n",
    "print list(reversed([e**2 for e in s]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
